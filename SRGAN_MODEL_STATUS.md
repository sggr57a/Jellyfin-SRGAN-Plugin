# SRGAN Model Status & Activation Guide

## ‚ö†Ô∏è Current Status: **AI Model NOT Active**

Your pipeline is currently using **basic FFmpeg lanczos scaling**, NOT the SRGAN AI model.

---

## üîç Why AI Model Isn't Running

### 1. SRGAN is Disabled

```yaml
# docker-compose.yml line 28
environment:
  - SRGAN_ENABLE=0  # ‚ùå Disabled (0 = ffmpeg fallback)
```

### 2. No Model Weights

```bash
# Expected model file doesn't exist
models/swift_srgan_4x.pth  # ‚ùå Missing
```

### 3. Current Behavior

```python
# scripts/srgan_pipeline.py (lines 322-337)
enable_model = os.environ.get("SRGAN_ENABLE", "0") == "1"
used_model = False

if enable_model:
    used_model = _try_model(...)  # Will fail - no model file
    
if not used_model:
    # ‚úÖ Falls back to FFmpeg lanczos
    _run_ffmpeg_streaming(...)
```

**Result:** Basic 2x scaling with Lanczos interpolation

---

## üìä Comparison: Lanczos vs SRGAN

| Feature | **Current (Lanczos)** | **SRGAN AI Model** |
|---------|---------------------|-------------------|
| **Method** | Mathematical interpolation | Deep learning neural network |
| **Quality** | Smooth but soft edges | Sharp details, texture reconstruction |
| **Speed** | Very fast (GPU encoding) | Slower (GPU inference + encoding) |
| **GPU Usage** | Encoding only | Inference + encoding |
| **File Size** | N/A | Needs ~100-500MB model weights |
| **Setup** | ‚úÖ Ready now | Needs model download |

### Visual Difference

**Lanczos (Current):**
- Smooth gradients
- Blurry edges
- No new detail creation
- Good for clean upscaling
- Fast processing

**SRGAN AI:**
- Sharper edges
- Reconstructed textures
- Enhanced fine details
- Better for low-res sources
- 3-10x slower

---

## üöÄ Option 1: Enable SRGAN AI Model

### Prerequisites

1. **CUDA-capable GPU** ‚úÖ (You have it)
2. **Model weights file** ‚ùå (Need to download)
3. **PyTorch + torchaudio** (Need to verify in container)

### Step 1: Download Model Weights

```bash
# On your server
ssh root@192.168.101.164
cd /root/Jellyfin-SRGAN-Plugin

# Create models directory
mkdir -p models

# Download Swift-SRGAN 4x model
# Option A: Use setup script
./scripts/setup_model.sh

# Option B: Manual download from GitHub
# https://github.com/Koushik0901/Swift-SRGAN
# Download swift_srgan_4x.pth to models/
```

**Popular SRGAN Models:**

| Model | Scale | Size | Source |
|-------|-------|------|--------|
| **Swift-SRGAN 4x** | 4x | ~16MB | [GitHub](https://github.com/Koushik0901/Swift-SRGAN) |
| **Real-ESRGAN 4x** | 4x | ~65MB | [GitHub](https://github.com/xinntao/Real-ESRGAN) |
| **ESRGAN 4x** | 4x | ~65MB | [GitHub](https://github.com/xinntao/ESRGAN) |

### Step 2: Verify PyTorch in Container

```bash
# Check if PyTorch is installed
docker compose exec srgan-upscaler python3 -c "import torch; print(torch.__version__)"
docker compose exec srgan-upscaler python3 -c "import torchaudio; print(torchaudio.__version__)"

# If missing, update Dockerfile to add:
# RUN pip3 install torch torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Step 3: Enable SRGAN in docker-compose.yml

```bash
# Edit docker-compose.yml
nano docker-compose.yml

# Change line 28:
# FROM:
- SRGAN_ENABLE=0

# TO:
- SRGAN_ENABLE=1
```

### Step 4: Rebuild and Restart

```bash
cd /root/Jellyfin-SRGAN-Plugin

# Rebuild container
docker compose build srgan-upscaler

# Restart
docker compose down
docker compose up -d

# Verify
docker logs srgan-upscaler
```

### Step 5: Test

```bash
# Test with a file
sudo ./scripts/test_upscaling.sh '/mnt/media/MOVIES/...'

# Check logs for AI model usage
docker logs srgan-upscaler 2>&1 | grep -i "model\|srgan\|loading"

# Should see:
# "Loading SRGAN model from /app/models/swift_srgan_4x.pth"
# "Using device: cuda"
```

---

## üéØ Option 2: Keep Using FFmpeg (Current)

If you're happy with the current quality and speed, **no action needed**.

### Advantages of Staying with Lanczos

‚úÖ **Much faster** - Real-time processing  
‚úÖ **Lower GPU usage** - Only encoding  
‚úÖ **No model downloads** - Simpler setup  
‚úÖ **Good quality** - For already high-res sources  
‚úÖ **Already working** - No changes needed  

### When Lanczos is Good Enough

- Source is already 1080p+ (upscaling to 4K)
- You want fast real-time streaming
- Content is modern, clean encodes
- You prioritize speed over maximum quality

### When You Need SRGAN AI

- Source is low-res (480p, 720p to 4K)
- Old movies, anime, low-bitrate content
- Want maximum detail enhancement
- Processing time is not critical
- Willing to trade speed for quality

---

## üß™ Performance Comparison

### Test File: 1080p Movie (2 hours)

| Method | Processing Time | GPU Usage | Quality Score |
|--------|----------------|-----------|---------------|
| **Lanczos (Current)** | 2-4 hours | 30-50% | 7/10 |
| **SRGAN AI** | 6-24 hours | 80-95% | 9/10 |

**Speed depends on:**
- GPU model (T4, P100, V100, etc.)
- Source resolution
- Target scale factor
- FP16 vs FP32

---

## üîç How to Check What's Being Used

### Method 1: Check Logs

```bash
# Check container logs
docker logs srgan-upscaler 2>&1 | head -50

# Look for:
# ‚úÖ AI Model: "Loading SRGAN model..."
# ‚ùå FFmpeg: "Using streaming mode (HLS)" or "Using batch mode"
```

### Method 2: Check GPU Usage

```bash
# Monitor GPU
watch -n 1 nvidia-smi

# With AI Model:
# - High Memory Usage: 2-8GB VRAM
# - High GPU Utilization: 80-95%
# - Process: python3

# With FFmpeg Only:
# - Lower Memory: 500MB-2GB VRAM
# - Medium GPU: 30-50%
# - Process: ffmpeg
```

### Method 3: Check Processing Speed

```bash
# Watch output directory
watch -n 2 'ls -lh /root/Jellyfin-SRGAN-Plugin/upscaled/hls/*/'

# FFmpeg (fast):
# - New segment every 6-12 seconds
# - About 1x real-time speed

# AI Model (slow):
# - New segment every 30-120 seconds
# - About 0.1-0.3x real-time speed
```

---

## üìã Summary

| Question | Answer |
|----------|--------|
| **Is SRGAN AI being used?** | ‚ùå No, currently using FFmpeg lanczos |
| **Does SRGAN code exist?** | ‚úÖ Yes, in `your_model_file.py` |
| **Is it functional?** | ‚úÖ Yes, just needs model weights + enable |
| **Do you need to change?** | ‚ùì Depends on your quality requirements |

---

## üöÄ Quick Decision Guide

### Stay with FFmpeg (Current) if:
- ‚úÖ Quality is acceptable
- ‚úÖ Speed is important
- ‚úÖ Sources are already high-res
- ‚úÖ Want simplicity

### Switch to SRGAN AI if:
- ‚ùå Quality isn't good enough
- ‚úÖ Have time to process
- ‚úÖ Upscaling low-res content
- ‚úÖ Want maximum detail

---

## üìñ Files Involved

| File | Purpose | Status |
|------|---------|--------|
| `docker-compose.yml` | Enable/disable SRGAN | SRGAN_ENABLE=0 |
| `scripts/your_model_file.py` | AI model code | ‚úÖ Ready |
| `scripts/srgan_pipeline.py` | Pipeline logic | ‚úÖ Working |
| `models/swift_srgan_4x.pth` | Model weights | ‚ùå Missing |
| `Dockerfile` | Container setup | May need PyTorch |

---

## üéØ Next Steps

### To Enable AI Model:
```bash
# 1. Download model
./scripts/setup_model.sh

# 2. Enable in docker-compose.yml
sed -i 's/SRGAN_ENABLE=0/SRGAN_ENABLE=1/' docker-compose.yml

# 3. Rebuild
docker compose build --no-cache srgan-upscaler
docker compose up -d

# 4. Test
sudo ./scripts/test_upscaling.sh '/path/to/file.mp4'
```

### To Keep Current Setup:
```bash
# Nothing to do - already working!
# Just continue using Jellyfin normally
```

---

## ‚ùì Questions?

**Q: Will enabling AI model break current setup?**  
A: No, it falls back to FFmpeg if model fails to load.

**Q: Can I switch back and forth?**  
A: Yes, just change `SRGAN_ENABLE` and restart container.

**Q: Which is better?**  
A: Depends on your content and priorities. Try both!

**Q: How much slower is AI model?**  
A: Typically 3-10x slower than FFmpeg-only.

**Q: Will it look much better?**  
A: Depends on source quality. Most noticeable with low-res content.
